{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/goudarzimandanagmail.com/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accessing files\n",
    "import os\n",
    "\n",
    "#manipulation libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "#for python object structure\n",
    "import pickle\n",
    "\n",
    "#biopython for parsing the cif files and manipulation of the cif files\n",
    "from Bio.PDB.MMCIFParser import MMCIFParser\n",
    "from Bio.PDB import PDBIO\n",
    "from Bio import PDB\n",
    "\n",
    "#data structures for manipulation\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "#transformer model for embedding space creation\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "#gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embedding model initialization\n",
    "tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False ) # change model and tokenizer to t5\n",
    "model_embedd = BertModel.from_pretrained(\"Rostlab/prot_bert\")\n",
    "model_embedd = model_embedd.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequence, angle and embedding processing\n",
    "def extract_input(pdb_file, model, tokenizer,data):\n",
    "    '''\n",
    "    Input =>\n",
    "    pdb_file : file containing all the information for the given protein (.pdb or .cif)\n",
    "    tokenizer : tokenizer for the sequence tokenization\n",
    "    model : transformer model used for creating embedding space\n",
    "    data : data nickname wanted to be extracted (alphafold, pisces)\n",
    "    \n",
    "    Output =>\n",
    "    sequence : extracted from the file\n",
    "    angle_tensor : tensor containing phi and psi angles for the given sequence\n",
    "    embeddings : embedding created using the model for the given sequence\n",
    "    '''\n",
    "    #print('Data folder used:',data)\n",
    "    #Parsing the cif file\n",
    "    cif_parser = MMCIFParser()\n",
    "    structure = cif_parser.get_structure(\"protein\", pdb_file) # getting structure\n",
    "    model0 = structure[0]\n",
    "\n",
    "    #This is a very common need in bioinformatics of proteins\n",
    "    d3to1 = {'CYS': 'C', 'ASP': 'D', 'SER': 'S', 'GLN': 'Q', 'LYS': 'K',\n",
    "    'ILE': 'I', 'PRO': 'P', 'THR': 'T', 'PHE': 'F', 'ASN': 'N',\n",
    "    'GLY': 'G', 'HIS': 'H', 'LEU': 'L', 'ARG': 'R', 'TRP': 'W',\n",
    "    'ALA': 'A', 'VAL':'V', 'GLU': 'E', 'TYR': 'Y', 'MET': 'M'}\n",
    "\n",
    "    if data=='pisces':\n",
    "        #This is to access the dictionary keys, which are the same as the file name, \n",
    "        #Once the keys are accessed we can find which chain to take\n",
    "        mapping_file = os.path.join('data_processed/new_training/pdb_id_mapping.csv') \n",
    "\n",
    "        pdb_id_map = pd.read_csv(mapping_file, header=None, index_col=0).squeeze().to_dict()\n",
    "\n",
    "        #extracting the file name as it contains the id\n",
    "        filename = os.path.basename(pdb_file)\n",
    "        pdb_id = filename[:4] # the first 4 letters of the file name is the dictionary key,whose value is the chain to be used\n",
    "\n",
    "        full_pdb_id = pdb_id_map.get(pdb_id, None) #pdb id with the correct chain\n",
    "\n",
    "        chain_A = model0[full_pdb_id[-1]]  # and we get chain A , the last letter of the id is the chain\n",
    "        print(\"Full pdb id: \", full_pdb_id)\n",
    "\n",
    "        #Creating a dictionary to collect chain ids and turn them into indices\n",
    "        chain_id_to_num = {}\n",
    "        for num, chain in enumerate(model0.get_chains()):\n",
    "            chain_id_to_num[chain.id] = num\n",
    "\n",
    "        #Iterator of chains, turns it into list, [0] first chain\n",
    "        chain:PDB.Chain.Chain = list(model0.get_chains())[chain_id_to_num.get(full_pdb_id[-1])]\n",
    "\n",
    "    elif data=='alphafold':\n",
    "        chain_A = model0['A']\n",
    "        #Iterator of chains, turns it into list, [0] first chain\n",
    "        chain:PDB.Chain.Chain = list(model0.get_chains())[0]\n",
    "\n",
    "    sequence = []\n",
    "    for residue in chain_A:\n",
    "        #For simplicity we can use X for heteroatoms (ions and water)\n",
    "        sequence.append(d3to1.get(residue.get_resname(), 'X'))  #converts water and ions to X\n",
    "    \n",
    "    structure.atom_to_internal_coordinates() # turns xyz coordinates into angles and bond lengths\n",
    "\n",
    "    #This accesses the internal chain coords of the chain object\n",
    "    ic_chain: PDB.internal_coords.IC_Chain = chain.internal_coord \n",
    "\n",
    "    d: Dict[Tuple[PDB.internal_coords.AtomKey,\n",
    "              PDB.internal_coords.AtomKey,\n",
    "              PDB.internal_coords.AtomKey,\n",
    "              PDB.internal_coords.AtomKey],\n",
    "        PDB.internal_coords.Dihedron] = ic_chain.dihedra\n",
    "\n",
    "    phi_angles_list = []\n",
    "    psi_angles_list = []\n",
    "\n",
    "    for key in d:\n",
    "      if key[0].akl[3] == 'N' and key[1].akl[3] == 'CA' and key[2].akl[3] == 'C' and key[3].akl[3] == 'N':\n",
    "          phi_angles_list.append(d[key].angle)\n",
    "      elif key[0].akl[3] == 'C' and key[1].akl[3] == 'N' and key[2].akl[3] == 'CA' and key[3].akl[3] == 'C':\n",
    "        psi_angles_list.append(d[key].angle)\n",
    "\n",
    "    structure.internal_to_atom_coordinates(verbose = False)\n",
    "    io = PDBIO() #this is to write a pdb/cif file again\n",
    "    io.set_structure(structure)#setting the structure to the desired strcuture in the given file\n",
    "    phi_angles_list.append(0)\n",
    "    psi_angles_list.append(0)\n",
    "\n",
    "    phi = np.asarray(phi_angles_list,dtype=np.float32)\n",
    "    psi = np.asarray(psi_angles_list,dtype=np.float32)\n",
    "    angles = np.vstack((psi,phi))\n",
    "    angle_tensor = torch.tensor(angles, dtype=torch.float32).to(device)\n",
    "\n",
    "    #Encoding the sequence\n",
    "    encoded_input = tokenizer.encode(sequence,return_tensors='pt').to(device)  \n",
    "\n",
    "    #Create the embedding using the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=encoded_input)\n",
    "\n",
    "    #Cropping the embedding created because of the added start and end paddings\n",
    "    start_index = 1\n",
    "    end_index = len(sequence) + 1\n",
    "    embeddings = outputs.last_hidden_state[:,start_index:end_index,:]\n",
    "    #print('Embedding length: ',embeddings.size())\n",
    "\n",
    "    return sequence, angle_tensor, embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data path\n",
    "alphafold_path = 'alphafold_data2'\n",
    "#Processed data path\n",
    "target_alpha_path = 'data_processed/alphafold_training/'\n",
    "\n",
    "#Data path\n",
    "pisces_path = 'data/small_proteins'\n",
    "#Processed data path\n",
    "target_pisces_path = 'data_processed/pisces_training/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procces_data(directory_path, target_path,data):\n",
    "\n",
    "    embeddings_file = os.path.join(target_path, 'embeddings.pt')\n",
    "    angles_file = os.path.join(target_path, 'angles.pt')\n",
    "    sequences_file = os.path.join(target_path, 'sequences.pkl') \n",
    "    \n",
    "    #Embeddings tensor and angles tensor initialized with zero tensors\n",
    "    #The calculated values are concatenated, this way the padding is achieved to have equal length for each sequence\n",
    "    #129(max_length)\n",
    "    embeddings = torch.zeros(0, 129, 1024).to(device) \n",
    "    angles = torch.zeros(0, 2, 129).to(device)\n",
    "    sequences = []\n",
    "\n",
    "    def pad_sequence(sequence, target_length=129, pad_char=\"X\"):\n",
    "        padding_length = target_length - len(sequence)\n",
    "        padding = [pad_char] * padding_length\n",
    "        return sequence + padding\n",
    "\n",
    "    #Get list of files in the directory containing pdb/cif files\n",
    "    file_list = os.listdir(directory_path)\n",
    "\n",
    "    for i,filename in enumerate(file_list):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "    \n",
    "        #Extracting the information from the files\n",
    "        sequence, angle, embedding= extract_input(file_path, model_embedd, tokenizer,data)\n",
    "        if sequence is None or embedding is None or angle is None:\n",
    "            print(f\"Skipping {file_path} due to missing data\")\n",
    "            continue\n",
    "        print('Length of the sequence: ',len(sequence))\n",
    "\n",
    "        \n",
    "        padded_sequence = pad_sequence(sequence)\n",
    "        sequences.append(padded_sequence)\n",
    "\n",
    "        #Append the new data to the existing tensors\n",
    "        embedding_length = min(embedding.size(1), 129)\n",
    "        if i >= embeddings.size(0):\n",
    "            embeddings = torch.cat([embeddings.to(device), torch.zeros(1, 129, 1024).to(device)], dim=0)\n",
    "        \n",
    "        embeddings[i, :embedding_length] = embedding[ :, :]\n",
    "        angle_length = min(angle.size(1), 129)\n",
    "        if i >= angles.size(0):\n",
    "            angles = torch.cat([angles.to(device), torch.zeros(1, 2, 129).to(device)], dim=0)\n",
    "        \n",
    "        angles[i, :, :angle_length] = angle[:, :]\n",
    "        print('Loop number: ',i)\n",
    "        \n",
    "    \n",
    "    #Saving the updated tensors back to the files\n",
    "    torch.save(embeddings, embeddings_file)\n",
    "    torch.save(angles, angles_file)\n",
    "\n",
    "    #Saving the sequence\n",
    "    with open(sequences_file, 'wb') as f:\n",
    "        pickle.dump(sequences, f)\n",
    "\n",
    "    return angle, angles, embeddings, embedding, sequences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the angles:  torch.Size([1711, 2, 129])\n",
      "Size of the embeddings:  torch.Size([1711, 129, 1024])\n",
      "Number of sequences in total:  1711\n"
     ]
    }
   ],
   "source": [
    "#Importing processed PISCES data\n",
    "pisces_angles = torch.load('/Users/goudarzimandanagmail.com/Desktop/TransformerFromScratch/data_processed/pisces_training/angles.pt', map_location=torch.device('cpu'))\n",
    "pisces_embeddings = torch.load('/Users/goudarzimandanagmail.com/Desktop/TransformerFromScratch/data_processed/pisces_training/embeddings.pt', map_location=torch.device('cpu'))\n",
    "with open('/Users/goudarzimandanagmail.com/Desktop/TransformerFromScratch/data_processed/pisces_training/sequences.pkl', 'rb') as f:\n",
    "        pisces_sequences = pickle.load(f)\n",
    "\n",
    "#Loading data to the device\n",
    "#pisces_angles = pisces_angles.to(device)\n",
    "#pisces_embeddings = pisces_embeddings.to(device)\n",
    "\n",
    "print(\"Size of the angles: \",pisces_angles.size())\n",
    "print(\"Size of the embeddings: \",pisces_embeddings.size())\n",
    "print(\"Number of sequences in total: \",len(pisces_sequences)) \n",
    "\n",
    "\n",
    "pisces_sequences = pisces_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the angles:  torch.Size([1000, 2, 129])\n",
      "Size of the embeddings:  torch.Size([1000, 129, 1024])\n",
      "Number of sequences in total:  2630\n"
     ]
    }
   ],
   "source": [
    "#Importing processed AlphaFold data\n",
    "alphafold_angles = torch.load('/Users/goudarzimandanagmail.com/Desktop/TransformerFromScratch/data_processed/alphafold_training/angles.pt', map_location=torch.device('cpu'))\n",
    "alphafold_embeddings = torch.load('/Users/goudarzimandanagmail.com/Desktop/TransformerFromScratch/data_processed/alphafold_training/embeddings.pt', map_location=torch.device('cpu'))\n",
    "with open('/Users/goudarzimandanagmail.com/Desktop/TransformerFromScratch/data_processed/alphafold_training/sequences.pkl', 'rb') as f:\n",
    "        alphafold_sequences = pickle.load(f)\n",
    "\n",
    "#Loading data to the device\n",
    "alphafold_angles = alphafold_angles[:1000,:,:].to(device)\n",
    "alphafold_embeddings = alphafold_embeddings[:1000,:,:].to(device)\n",
    "\n",
    "print(\"Size of the angles: \",alphafold_angles.size())\n",
    "print(\"Size of the embeddings: \",alphafold_embeddings.size())\n",
    "print(\"Number of sequences in total: \",len(alphafold_sequences))\n",
    "\n",
    "#print(alphafold_angles[2,:,:])\n",
    "alphafold_sequences = alphafold_sequences[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 'MSSSNTDNQYPKYINDTTPPTITLKEYDNASWASTTCLDHNPIKNQYIVVVMENPNQIVAIIDQQDNMILDILFKNAHDAHSKQEYSTK'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def extract_sequence_from_structure(file_path):\n",
    "    \"\"\"\n",
    "    Extracts protein sequences from a PDB or CIF file.\n",
    "    \n",
    "    Args:\n",
    "    file_path (str): Path to the PDB or CIF file.\n",
    "    \n",
    "    Returns:\n",
    "    sequences (dict): A dictionary where keys are chain identifiers and values are sequences.\n",
    "    \"\"\"\n",
    "    if file_path.endswith('.cif'):\n",
    "        parser = MMCIFParser()\n",
    "    else:\n",
    "        parser = PDBParser()\n",
    "    \n",
    "    structure = parser.get_structure('protein', file_path)\n",
    "    \n",
    "    sequences = {}\n",
    "    for model in structure:\n",
    "        for chain in model:\n",
    "            seq = ''\n",
    "            for residue in chain:\n",
    "                if residue.id[0] == ' ':  # Exclude hetero residues\n",
    "                    seq += PDB.Polypeptide.three_to_one(residue.resname)\n",
    "            sequences[chain.id] = seq\n",
    "    return sequences\n",
    "\n",
    "\n",
    "file_path = \"/Users/goudarzimandanagmail.com/Desktop/TransformerFromScratch/files/AF-A0A1D8PD42-F1-model_v4.cif\"\n",
    "sequences = extract_sequence_from_structure(file_path)\n",
    "print(sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry ID: AF-A0A1D8PD42-F1\n",
      "Authors: None\n",
      "Citation Title: \"Highly accurate protein structure prediction with AlphaFold\"\n",
      "Citation Year: 2021\n",
      "Journal: Nature\n",
      "DOI: 10.1038/s41586-021-03819-2\n",
      "country: UK\n",
      "Type: polymer\n",
      "Poly Type: polypeptide(L)\n",
      "Model Name: \"Top ranked model\"\n",
      "Model Type: \"Ab initio model\"\n",
      "pLDDT: 86.99\n",
      "Gene Name: orf19.1026.1\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def parse_cif(file_content):\n",
    "    metadata = defaultdict(list)\n",
    "    current_loop = None\n",
    "\n",
    "    for line in file_content:\n",
    "        line = line.strip()\n",
    "\n",
    "        # Skip empty lines\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        if line.startswith('_'):\n",
    "            parts = line.split(None, 1)\n",
    "            if len(parts) == 2:  # Ensure there are both key and value\n",
    "                key, value = parts\n",
    "                value = value.strip()\n",
    "                metadata[key].append(value)\n",
    "            current_loop = None\n",
    "        \n",
    "        elif line.startswith('loop_'):\n",
    "            current_loop = []\n",
    "        \n",
    "        elif current_loop is not None:\n",
    "            current_loop.append(line.strip().split())\n",
    "\n",
    "    return dict(metadata)\n",
    "\n",
    "def extract_specific_metadata(metadata):\n",
    "    extracted_data = {}\n",
    "\n",
    "    # Extract entry ID\n",
    "    extracted_data['Entry ID'] = metadata.get('_entry.id', [None])[0]\n",
    "\n",
    "    # Extract authors\n",
    "    authors = metadata.get('_citation_author.name', [])\n",
    "    extracted_data['Authors'] = authors\n",
    "\n",
    "    # Extract citation details\n",
    "    # extracted_data['Authors'] = metadata.get('_citation_author.name', [None])[0]\n",
    "    extracted_data['Citation Title'] = metadata.get('_citation.title', [None])[0]\n",
    "    extracted_data['Citation Year'] = metadata.get('_citation.year', [None])[0]\n",
    "    extracted_data['Journal'] = metadata.get('_citation.journal_full', [None])[0]\n",
    "    extracted_data['DOI'] = metadata.get('_citation.pdbx_database_id_DOI', [None])[0]\n",
    "    extracted_data['country'] = metadata.get('_citation.country', [None])[0]\n",
    "\n",
    "    # Extract model details\n",
    "    extracted_data['Type'] = metadata.get('_entity.type', [None])[0]\n",
    "    extracted_data['Poly Type'] = metadata.get('_entity_poly.type', [None])[0]\n",
    "    extracted_data['Model Name'] = metadata.get('_ma_model_list.model_name', [None])[0]\n",
    "    extracted_data['Model Type'] = metadata.get('_ma_model_list.model_type', [None])[0]\n",
    "    extracted_data['pLDDT'] = metadata.get('_ma_qa_metric_global.metric_value', [None])[0]\n",
    "    extracted_data['Gene Name'] = metadata.get('_ma_target_ref_db_details.gene_name', [None])[0]\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "cif_file_path = \"/Users/goudarzimandanagmail.com/Desktop/TransformerFromScratch/files/AF-A0A1D8PD42-F1-model_v4.cif\"\n",
    "with open(cif_file_path, 'r') as file:\n",
    "    file_content = file.readlines()\n",
    "\n",
    "\n",
    "metadata = parse_cif(file_content)\n",
    "\n",
    "extracted_metadata = extract_specific_metadata(metadata)\n",
    "\n",
    "for key, value in extracted_metadata.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 1:\n",
      "_entry.id AF-A0A1D8PD42-F1\n",
      "--------------------------------------------------\n",
      "Block 2:\n",
      "loop_\n",
      "_audit_author.name\n",
      "_audit_author.pdbx_ordinal\n",
      "\"Jumper, John\"               1\n",
      "\"Evans, Richard\"             2\n",
      "\"Pritzel, Alexander\"         3\n",
      "\"Green, Tim\"                 4\n",
      "\"Figurnov, Michael\"          5\n",
      "\"Ronneberger, Olaf\"          6\n",
      "\"Tunyasuvunakool, Kathryn\"   7\n",
      "\"Bates, Russ\"                8\n",
      "\"Zidek, Augustin\"            9\n",
      "\"Potapenko, Anna\"            10\n",
      "\"Bridgland, Alex\"            11\n",
      "\"Meyer, Clemens\"             12\n",
      "\"Kohl, Simon A. A.\"          13\n",
      "\"Ballard, Andrew J.\"         14\n",
      "\"Cowie, Andrew\"              15\n",
      "\"Romera-Paredes, Bernardino\" 16\n",
      "\"Nikolov, Stanislav\"         17\n",
      "\"Jain, Rishub\"               18\n",
      "\"Adler, Jonas\"               19\n",
      "\"Back, Trevor\"               20\n",
      "\"Petersen, Stig\"             21\n",
      "\"Reiman, David\"              22\n",
      "\"Clancy, Ellen\"              23\n",
      "\"Zielinski, Michal\"          24\n",
      "\"Steinegger, Martin\"         25\n",
      "\"Pacholska, Michalina\"       26\n",
      "\"Berghammer, Tamas\"          27\n",
      "\"Silver, David\"              28\n",
      "\"Vinyals, Oriol\"             29\n",
      "\"Senior, Andrew W.\"          30\n",
      "\"Kavukcuoglu, Koray\"         31\n",
      "\"Kohli, Pushmeet\"            32\n",
      "\"Hassabis, Demis\"            33\n",
      "--------------------------------------------------\n",
      "Block 3:\n",
      "loop_\n",
      "_chem_comp.formula\n",
      "_chem_comp.formula_weight\n",
      "_chem_comp.id\n",
      "_chem_comp.mon_nstd_flag\n",
      "_chem_comp.name\n",
      "_chem_comp.pdbx_synonyms\n",
      "_chem_comp.type\n",
      "\"C3 H7 N O2\"    89.093  ALA y ALANINE         ? \"L-PEPTIDE LINKING\"\n",
      "\"C4 H8 N2 O3\"   132.118 ASN y ASPARAGINE      ? \"L-PEPTIDE LINKING\"\n",
      "\"C4 H7 N O4\"    133.103 ASP y \"ASPARTIC ACID\" ? \"L-PEPTIDE LINKING\"\n",
      "\"C3 H7 N O2 S\"  121.158 CYS y CYSTEINE        ? \"L-PEPTIDE LINKING\"\n",
      "\"C5 H10 N2 O3\"  146.144 GLN y GLUTAMINE       ? \"L-PEPTIDE LINKING\"\n",
      "\"C5 H9 N O4\"    147.129 GLU y \"GLUTAMIC ACID\" ? \"L-PEPTIDE LINKING\"\n",
      "\"C6 H10 N3 O2\"  156.162 HIS y HISTIDINE       ? \"L-PEPTIDE LINKING\"\n",
      "\"C6 H13 N O2\"   131.173 ILE y ISOLEUCINE      ? \"L-PEPTIDE LINKING\"\n",
      "\"C6 H13 N O2\"   131.173 LEU y LEUCINE         ? \"L-PEPTIDE LINKING\"\n",
      "\"C6 H15 N2 O2\"  147.195 LYS y LYSINE          ? \"L-PEPTIDE LINKING\"\n",
      "\"C5 H11 N O2 S\" 149.211 MET y METHIONINE      ? \"L-PEPTIDE LINKING\"\n",
      "\"C9 H11 N O2\"   165.189 PHE y PHENYLALANINE   ? \"L-PEPTIDE LINKING\"\n",
      "\"C5 H9 N O2\"    115.130 PRO y PROLINE         ? \"L-PEPTIDE LINKING\"\n",
      "\"C3 H7 N O3\"    105.093 SER y SERINE          ? \"L-PEPTIDE LINKING\"\n",
      "\"C4 H9 N O3\"    119.119 THR y THREONINE       ? \"L-PEPTIDE LINKING\"\n",
      "\"C11 H12 N2 O2\" 204.225 TRP y TRYPTOPHAN      ? \"L-PEPTIDE LINKING\"\n",
      "\"C9 H11 N O3\"   181.189 TYR y TYROSINE        ? \"L-PEPTIDE LINKING\"\n",
      "\"C5 H11 N O2\"   117.146 VAL y VALINE          ? \"L-PEPTIDE LINKING\"\n",
      "--------------------------------------------------\n",
      "Block 4:\n",
      "loop_\n",
      "_citation_author.citation_id\n",
      "_citation_author.name\n",
      "_citation_author.ordinal\n",
      "1 \"Jumper, John\"               1\n",
      "1 \"Evans, Richard\"             2\n",
      "1 \"Pritzel, Alexander\"         3\n",
      "1 \"Green, Tim\"                 4\n",
      "1 \"Figurnov, Michael\"          5\n",
      "1 \"Ronneberger, Olaf\"          6\n",
      "1 \"Tunyasuvunakool, Kathryn\"   7\n",
      "1 \"Bates, Russ\"                8\n",
      "1 \"Zidek, Augustin\"            9\n",
      "1 \"Potapenko, Anna\"            10\n",
      "1 \"Bridgland, Alex\"            11\n",
      "1 \"Meyer, Clemens\"             12\n",
      "1 \"Kohl, Simon A. A.\"          13\n",
      "1 \"Ballard, Andrew J.\"         14\n",
      "1 \"Cowie, Andrew\"              15\n",
      "1 \"Romera-Paredes, Bernardino\" 16\n",
      "1 \"Nikolov, Stanislav\"         17\n",
      "1 \"Jain, Rishub\"               18\n",
      "1 \"Adler, Jonas\"               19\n",
      "1 \"Back, Trevor\"               20\n",
      "1 \"Petersen, Stig\"             21\n",
      "1 \"Reiman, David\"              22\n",
      "1 \"Clancy, Ellen\"              23\n",
      "1 \"Zielinski, Michal\"          24\n",
      "1 \"Steinegger, Martin\"         25\n",
      "1 \"Pacholska, Michalina\"       26\n",
      "1 \"Berghammer, Tamas\"          27\n",
      "1 \"Silver, David\"              28\n",
      "1 \"Vinyals, Oriol\"             29\n",
      "1 \"Senior, Andrew W.\"          30\n",
      "1 \"Kavukcuoglu, Koray\"         31\n",
      "1 \"Kohli, Pushmeet\"            32\n",
      "1 \"Hassabis, Demis\"            33\n",
      "--------------------------------------------------\n",
      "Block 5:\n",
      "_entity.details                  ?\n",
      "_entity.formula_weight           ?\n",
      "_entity.id                       1\n",
      "_entity.pdbx_description         \"Uncharacterized protein\"\n",
      "_entity.pdbx_ec                  ?\n",
      "_entity.pdbx_fragment            ?\n",
      "_entity.pdbx_mutation            ?\n",
      "_entity.pdbx_number_of_molecules 1\n",
      "_entity.src_method               man\n",
      "_entity.type                     polymer\n",
      "--------------------------------------------------\n",
      "Block 6:\n",
      "loop_\n",
      "_entity_poly_seq.entity_id\n",
      "_entity_poly_seq.hetero\n",
      "_entity_poly_seq.mon_id\n",
      "_entity_poly_seq.num\n",
      "1 n MET 1\n",
      "1 n SER 2\n",
      "1 n SER 3\n",
      "1 n SER 4\n",
      "1 n ASN 5\n",
      "1 n THR 6\n",
      "1 n ASP 7\n",
      "1 n ASN 8\n",
      "1 n GLN 9\n",
      "1 n TYR 10\n",
      "1 n PRO 11\n",
      "1 n LYS 12\n",
      "1 n TYR 13\n",
      "1 n ILE 14\n",
      "1 n ASN 15\n",
      "1 n ASP 16\n",
      "1 n THR 17\n",
      "1 n THR 18\n",
      "1 n PRO 19\n",
      "1 n PRO 20\n",
      "1 n THR 21\n",
      "1 n ILE 22\n",
      "1 n THR 23\n",
      "1 n LEU 24\n",
      "1 n LYS 25\n",
      "1 n GLU 26\n",
      "1 n TYR 27\n",
      "1 n ASP 28\n",
      "1 n ASN 29\n",
      "1 n ALA 30\n",
      "1 n SER 31\n",
      "1 n TRP 32\n",
      "1 n ALA 33\n",
      "1 n SER 34\n",
      "1 n THR 35\n",
      "1 n THR 36\n",
      "1 n CYS 37\n",
      "1 n LEU 38\n",
      "1 n ASP 39\n",
      "1 n HIS 40\n",
      "1 n ASN 41\n",
      "1 n PRO 42\n",
      "1 n ILE 43\n",
      "1 n LYS 44\n",
      "1 n ASN 45\n",
      "1 n GLN 46\n",
      "1 n TYR 47\n",
      "1 n ILE 48\n",
      "1 n VAL 49\n",
      "1 n VAL 50\n",
      "1 n VAL 51\n",
      "1 n MET 52\n",
      "1 n GLU 53\n",
      "1 n ASN 54\n",
      "1 n PRO 55\n",
      "1 n ASN 56\n",
      "1 n GLN 57\n",
      "1 n ILE 58\n",
      "1 n VAL 59\n",
      "1 n ALA 60\n",
      "1 n ILE 61\n",
      "1 n ILE 62\n",
      "1 n ASP 63\n",
      "1 n GLN 64\n",
      "1 n GLN 65\n",
      "1 n ASP 66\n",
      "1 n ASN 67\n",
      "1 n MET 68\n",
      "1 n ILE 69\n",
      "1 n LEU 70\n",
      "1 n ASP 71\n",
      "1 n ILE 72\n",
      "1 n LEU 73\n",
      "1 n PHE 74\n",
      "1 n LYS 75\n",
      "1 n ASN 76\n",
      "1 n ALA 77\n",
      "1 n HIS 78\n",
      "1 n ASP 79\n",
      "1 n ALA 80\n",
      "1 n HIS 81\n",
      "1 n SER 82\n",
      "1 n LYS 83\n",
      "1 n GLN 84\n",
      "1 n GLU 85\n",
      "1 n TYR 86\n",
      "1 n SER 87\n",
      "1 n THR 88\n",
      "1 n LYS 89\n",
      "--------------------------------------------------\n",
      "Block 7:\n",
      "_ma_model_list.data_id          1\n",
      "_ma_model_list.model_group_id   1\n",
      "_ma_model_list.model_group_name \"AlphaFold Monomer v2.0 model\"\n",
      "_ma_model_list.model_id         1\n",
      "_ma_model_list.model_name       \"Top ranked model\"\n",
      "_ma_model_list.model_type       \"Ab initio model\"\n",
      "_ma_model_list.ordinal_id       1\n",
      "--------------------------------------------------\n",
      "Block 8:\n",
      "loop_\n",
      "_ma_qa_metric.id\n",
      "_ma_qa_metric.mode\n",
      "_ma_qa_metric.name\n",
      "_ma_qa_metric.software_group_id\n",
      "_ma_qa_metric.type\n",
      "1 global pLDDT 1 pLDDT\n",
      "2 local  pLDDT 1 pLDDT\n",
      "--------------------------------------------------\n",
      "Block 9:\n",
      "loop_\n",
      "_ma_qa_metric_local.label_asym_id\n",
      "_ma_qa_metric_local.label_comp_id\n",
      "_ma_qa_metric_local.label_seq_id\n",
      "_ma_qa_metric_local.metric_id\n",
      "_ma_qa_metric_local.metric_value\n",
      "_ma_qa_metric_local.model_id\n",
      "_ma_qa_metric_local.ordinal_id\n",
      "A MET 1  2 38.76 1 1\n",
      "A SER 2  2 42.05 1 2\n",
      "A SER 3  2 37.39 1 3\n",
      "A SER 4  2 42.83 1 4\n",
      "A ASN 5  2 46.46 1 5\n",
      "A THR 6  2 48.81 1 6\n",
      "A ASP 7  2 54.38 1 7\n",
      "A ASN 8  2 62.10 1 8\n",
      "A GLN 9  2 85.01 1 9\n",
      "A TYR 10 2 92.06 1 10\n",
      "A PRO 11 2 91.31 1 11\n",
      "A LYS 12 2 91.83 1 12\n",
      "A TYR 13 2 94.61 1 13\n",
      "A ILE 14 2 91.08 1 14\n",
      "A ASN 15 2 89.43 1 15\n",
      "A ASP 16 2 86.20 1 16\n",
      "A THR 17 2 88.56 1 17\n",
      "A THR 18 2 93.25 1 18\n",
      "A PRO 19 2 95.41 1 19\n",
      "A PRO 20 2 97.25 1 20\n",
      "A THR 21 2 97.70 1 21\n",
      "A ILE 22 2 97.49 1 22\n",
      "A THR 23 2 97.54 1 23\n",
      "A LEU 24 2 96.65 1 24\n",
      "A LYS 25 2 96.29 1 25\n",
      "A GLU 26 2 97.37 1 26\n",
      "A TYR 27 2 96.57 1 27\n",
      "A ASP 28 2 94.67 1 28\n",
      "A ASN 29 2 94.91 1 29\n",
      "A ALA 30 2 94.85 1 30\n",
      "A SER 31 2 94.85 1 31\n",
      "A TRP 32 2 94.34 1 32\n",
      "A ALA 33 2 95.62 1 33\n",
      "A SER 34 2 94.69 1 34\n",
      "A THR 35 2 94.89 1 35\n",
      "A THR 36 2 96.54 1 36\n",
      "A CYS 37 2 94.99 1 37\n",
      "A LEU 38 2 95.78 1 38\n",
      "A ASP 39 2 95.37 1 39\n",
      "A HIS 40 2 94.54 1 40\n",
      "A ASN 41 2 92.75 1 41\n",
      "A PRO 42 2 90.46 1 42\n",
      "A ILE 43 2 91.78 1 43\n",
      "A LYS 44 2 91.77 1 44\n",
      "A ASN 45 2 92.25 1 45\n",
      "A GLN 46 2 95.21 1 46\n",
      "A TYR 47 2 97.64 1 47\n",
      "A ILE 48 2 97.41 1 48\n",
      "A VAL 49 2 97.73 1 49\n",
      "A VAL 50 2 97.05 1 50\n",
      "A VAL 51 2 95.95 1 51\n",
      "A MET 52 2 94.18 1 52\n",
      "A GLU 53 2 94.53 1 53\n",
      "A ASN 54 2 94.43 1 54\n",
      "A PRO 55 2 93.85 1 55\n",
      "A ASN 56 2 93.22 1 56\n",
      "A GLN 57 2 94.43 1 57\n",
      "A ILE 58 2 95.93 1 58\n",
      "A VAL 59 2 96.27 1 59\n",
      "A ALA 60 2 97.58 1 60\n",
      "A ILE 61 2 97.77 1 61\n",
      "A ILE 62 2 97.95 1 62\n",
      "A ASP 63 2 97.31 1 63\n",
      "A GLN 64 2 95.85 1 64\n",
      "A GLN 65 2 96.33 1 65\n",
      "A ASP 66 2 96.10 1 66\n",
      "A ASN 67 2 93.28 1 67\n",
      "A MET 68 2 93.34 1 68\n",
      "A ILE 69 2 94.00 1 69\n",
      "A LEU 70 2 94.49 1 70\n",
      "A ASP 71 2 93.97 1 71\n",
      "A ILE 72 2 93.19 1 72\n",
      "A LEU 73 2 91.22 1 73\n",
      "A PHE 74 2 89.16 1 74\n",
      "A LYS 75 2 91.12 1 75\n",
      "A ASN 76 2 91.07 1 76\n",
      "A ALA 77 2 86.48 1 77\n",
      "A HIS 78 2 86.46 1 78\n",
      "A ASP 79 2 88.71 1 79\n",
      "A ALA 80 2 86.57 1 80\n",
      "A HIS 81 2 79.64 1 81\n",
      "A SER 82 2 81.88 1 82\n",
      "A LYS 83 2 77.29 1 83\n",
      "A GLN 84 2 69.83 1 84\n",
      "A GLU 85 2 62.18 1 85\n",
      "A TYR 86 2 56.90 1 86\n",
      "A SER 87 2 57.04 1 87\n",
      "A THR 88 2 55.11 1 88\n",
      "A LYS 89 2 47.29 1 89\n",
      "--------------------------------------------------\n",
      "Block 10:\n",
      "_ma_target_entity.data_id   1\n",
      "_ma_target_entity.entity_id 1\n",
      "_ma_target_entity.origin    \"reference database\"\n",
      "--------------------------------------------------\n",
      "Block 11:\n",
      "_ma_target_ref_db_details.db_accession                 A0A1D8PD42\n",
      "_ma_target_ref_db_details.db_code                      A0A1D8PD42_CANAL\n",
      "_ma_target_ref_db_details.db_name                      UNP\n",
      "_ma_target_ref_db_details.gene_name                    orf19.1026.1\n",
      "_ma_target_ref_db_details.ncbi_taxonomy_id             237561\n",
      "_ma_target_ref_db_details.organism_scientific          \"Candida albicans (strain SC5314 / ATCC MYA-2876)\"\n",
      "_ma_target_ref_db_details.seq_db_align_begin           1\n",
      "_ma_target_ref_db_details.seq_db_align_end             89\n",
      "_ma_target_ref_db_details.seq_db_isoform               ?\n",
      "_ma_target_ref_db_details.seq_db_sequence_checksum     C421565F5E9CE779\n",
      "_ma_target_ref_db_details.seq_db_sequence_version_date 2017-01-18\n",
      "_ma_target_ref_db_details.target_entity_id             1\n",
      "--------------------------------------------------\n",
      "Block 12:\n",
      "loop_\n",
      "_ma_template_ref_db_details.db_accession_code\n",
      "_ma_template_ref_db_details.db_name\n",
      "_ma_template_ref_db_details.template_id\n",
      "4Q0Y PDB 1\n",
      "4Q0Y PDB 2\n",
      "3N1S PDB 3\n",
      "3N1S PDB 4\n",
      "--------------------------------------------------\n",
      "Block 13:\n",
      "loop_\n",
      "_pdbx_audit_revision_details.data_content_type\n",
      "_pdbx_audit_revision_details.description\n",
      "_pdbx_audit_revision_details.ordinal\n",
      "_pdbx_audit_revision_details.provider\n",
      "_pdbx_audit_revision_details.revision_ordinal\n",
      "_pdbx_audit_revision_details.type\n",
      "\"Structure model\" ?                                                       1 repository 1 \"Initial release\"\n",
      "\"Structure model\" \"Format fixes, new metadata, initial SwissProt release\" 2 repository 2 Remediation\n",
      "\"Structure model\" \"Format fixes, new metadata, initial UniProt release\"   3 repository 3 Remediation\n",
      "\"Structure model\" \"Improved prediction accuracy, small format fixes\"      4 repository 4 Remediation\n",
      "--------------------------------------------------\n",
      "Block 14:\n",
      "loop_\n",
      "_pdbx_data_usage.details\n",
      "_pdbx_data_usage.id\n",
      "_pdbx_data_usage.name\n",
      "_pdbx_data_usage.type\n",
      "_pdbx_data_usage.url\n",
      "\"Data in this file is available under a CC-BY-4.0 license.\" 1 CC-BY-4.0 license    https://creativecommons.org/licenses/by/4.0/\n",
      ";ALPHAFOLD DATA, COPYRIGHT (2021) DEEPMIND TECHNOLOGIES LIMITED. THE INFORMATION\n",
      "PROVIDED IS THEORETICAL MODELLING ONLY AND CAUTION SHOULD BE EXERCISED IN ITS\n",
      "USE. IT IS PROVIDED \"AS-IS\" WITHOUT ANY WARRANTY OF ANY KIND, WHETHER EXPRESSED\n",
      "OR IMPLIED. NO WARRANTY IS GIVEN THAT USE OF THE INFORMATION SHALL NOT INFRINGE\n",
      "THE RIGHTS OF ANY THIRD PARTY. DISCLAIMER: THE INFORMATION IS NOT INTENDED TO BE\n",
      "A SUBSTITUTE FOR PROFESSIONAL MEDICAL ADVICE, DIAGNOSIS, OR TREATMENT, AND DOES\n",
      "NOT CONSTITUTE MEDICAL OR OTHER PROFESSIONAL ADVICE. IT IS AVAILABLE FOR\n",
      "ACADEMIC AND COMMERCIAL PURPOSES, UNDER CC-BY 4.0 LICENCE.\n",
      ";\n",
      "2 ?         disclaimer ?\n",
      "--------------------------------------------------\n",
      "Block 15:\n",
      "loop_\n",
      "_pdbx_poly_seq_scheme.asym_id\n",
      "_pdbx_poly_seq_scheme.auth_seq_num\n",
      "_pdbx_poly_seq_scheme.entity_id\n",
      "_pdbx_poly_seq_scheme.hetero\n",
      "_pdbx_poly_seq_scheme.mon_id\n",
      "_pdbx_poly_seq_scheme.pdb_ins_code\n",
      "_pdbx_poly_seq_scheme.pdb_mon_id\n",
      "_pdbx_poly_seq_scheme.pdb_seq_num\n",
      "_pdbx_poly_seq_scheme.pdb_strand_id\n",
      "_pdbx_poly_seq_scheme.seq_id\n",
      "A 1  1 n MET . MET 1  A 1\n",
      "A 2  1 n SER . SER 2  A 2\n",
      "A 3  1 n SER . SER 3  A 3\n",
      "A 4  1 n SER . SER 4  A 4\n",
      "A 5  1 n ASN . ASN 5  A 5\n",
      "A 6  1 n THR . THR 6  A 6\n",
      "A 7  1 n ASP . ASP 7  A 7\n",
      "A 8  1 n ASN . ASN 8  A 8\n",
      "A 9  1 n GLN . GLN 9  A 9\n",
      "A 10 1 n TYR . TYR 10 A 10\n",
      "A 11 1 n PRO . PRO 11 A 11\n",
      "A 12 1 n LYS . LYS 12 A 12\n",
      "A 13 1 n TYR . TYR 13 A 13\n",
      "A 14 1 n ILE . ILE 14 A 14\n",
      "A 15 1 n ASN . ASN 15 A 15\n",
      "A 16 1 n ASP . ASP 16 A 16\n",
      "A 17 1 n THR . THR 17 A 17\n",
      "A 18 1 n THR . THR 18 A 18\n",
      "A 19 1 n PRO . PRO 19 A 19\n",
      "A 20 1 n PRO . PRO 20 A 20\n",
      "A 21 1 n THR . THR 21 A 21\n",
      "A 22 1 n ILE . ILE 22 A 22\n",
      "A 23 1 n THR . THR 23 A 23\n",
      "A 24 1 n LEU . LEU 24 A 24\n",
      "A 25 1 n LYS . LYS 25 A 25\n",
      "A 26 1 n GLU . GLU 26 A 26\n",
      "A 27 1 n TYR . TYR 27 A 27\n",
      "A 28 1 n ASP . ASP 28 A 28\n",
      "A 29 1 n ASN . ASN 29 A 29\n",
      "A 30 1 n ALA . ALA 30 A 30\n",
      "A 31 1 n SER . SER 31 A 31\n",
      "A 32 1 n TRP . TRP 32 A 32\n",
      "A 33 1 n ALA . ALA 33 A 33\n",
      "A 34 1 n SER . SER 34 A 34\n",
      "A 35 1 n THR . THR 35 A 35\n",
      "A 36 1 n THR . THR 36 A 36\n",
      "A 37 1 n CYS . CYS 37 A 37\n",
      "A 38 1 n LEU . LEU 38 A 38\n",
      "A 39 1 n ASP . ASP 39 A 39\n",
      "A 40 1 n HIS . HIS 40 A 40\n",
      "A 41 1 n ASN . ASN 41 A 41\n",
      "A 42 1 n PRO . PRO 42 A 42\n",
      "A 43 1 n ILE . ILE 43 A 43\n",
      "A 44 1 n LYS . LYS 44 A 44\n",
      "A 45 1 n ASN . ASN 45 A 45\n",
      "A 46 1 n GLN . GLN 46 A 46\n",
      "A 47 1 n TYR . TYR 47 A 47\n",
      "A 48 1 n ILE . ILE 48 A 48\n",
      "A 49 1 n VAL . VAL 49 A 49\n",
      "A 50 1 n VAL . VAL 50 A 50\n",
      "A 51 1 n VAL . VAL 51 A 51\n",
      "A 52 1 n MET . MET 52 A 52\n",
      "A 53 1 n GLU . GLU 53 A 53\n",
      "A 54 1 n ASN . ASN 54 A 54\n",
      "A 55 1 n PRO . PRO 55 A 55\n",
      "A 56 1 n ASN . ASN 56 A 56\n",
      "A 57 1 n GLN . GLN 57 A 57\n",
      "A 58 1 n ILE . ILE 58 A 58\n",
      "A 59 1 n VAL . VAL 59 A 59\n",
      "A 60 1 n ALA . ALA 60 A 60\n",
      "A 61 1 n ILE . ILE 61 A 61\n",
      "A 62 1 n ILE . ILE 62 A 62\n",
      "A 63 1 n ASP . ASP 63 A 63\n",
      "A 64 1 n GLN . GLN 64 A 64\n",
      "A 65 1 n GLN . GLN 65 A 65\n",
      "A 66 1 n ASP . ASP 66 A 66\n",
      "A 67 1 n ASN . ASN 67 A 67\n",
      "A 68 1 n MET . MET 68 A 68\n",
      "A 69 1 n ILE . ILE 69 A 69\n",
      "A 70 1 n LEU . LEU 70 A 70\n",
      "A 71 1 n ASP . ASP 71 A 71\n",
      "A 72 1 n ILE . ILE 72 A 72\n",
      "A 73 1 n LEU . LEU 73 A 73\n",
      "A 74 1 n PHE . PHE 74 A 74\n",
      "A 75 1 n LYS . LYS 75 A 75\n",
      "A 76 1 n ASN . ASN 76 A 76\n",
      "A 77 1 n ALA . ALA 77 A 77\n",
      "A 78 1 n HIS . HIS 78 A 78\n",
      "A 79 1 n ASP . ASP 79 A 79\n",
      "A 80 1 n ALA . ALA 80 A 80\n",
      "A 81 1 n HIS . HIS 81 A 81\n",
      "A 82 1 n SER . SER 82 A 82\n",
      "A 83 1 n LYS . LYS 83 A 83\n",
      "A 84 1 n GLN . GLN 84 A 84\n",
      "A 85 1 n GLU . GLU 85 A 85\n",
      "A 86 1 n TYR . TYR 86 A 86\n",
      "A 87 1 n SER . SER 87 A 87\n",
      "A 88 1 n THR . THR 88 A 88\n",
      "A 89 1 n LYS . LYS 89 A 89\n",
      "--------------------------------------------------\n",
      "Block 16:\n",
      "_struct_asym.entity_id 1\n",
      "_struct_asym.id        A\n",
      "--------------------------------------------------\n",
      "Block 17:\n",
      "loop_\n",
      "_struct_conf_type.criteria\n",
      "_struct_conf_type.id\n",
      "DSSP HELX_LH_PP_P\n",
      "DSSP BEND\n",
      "DSSP STRN\n",
      "DSSP TURN_TY1_P\n",
      "DSSP HELX_RH_AL_P\n",
      "DSSP HELX_RH_3T_P\n",
      "--------------------------------------------------\n",
      "Block 18:\n",
      "_struct_ref_seq.align_id                    1\n",
      "_struct_ref_seq.db_align_beg                1\n",
      "_struct_ref_seq.db_align_end                89\n",
      "_struct_ref_seq.pdbx_PDB_id_code            AF-A0A1D8PD42-F1\n",
      "_struct_ref_seq.pdbx_auth_seq_align_beg     1\n",
      "_struct_ref_seq.pdbx_auth_seq_align_end     89\n",
      "_struct_ref_seq.pdbx_db_accession           A0A1D8PD42\n",
      "_struct_ref_seq.pdbx_db_align_beg_ins_code  ?\n",
      "_struct_ref_seq.pdbx_db_align_end_ins_code  ?\n",
      "_struct_ref_seq.pdbx_seq_align_beg_ins_code ?\n",
      "_struct_ref_seq.pdbx_seq_align_end_ins_code ?\n",
      "_struct_ref_seq.pdbx_strand_id              A\n",
      "_struct_ref_seq.ref_id                      1\n",
      "_struct_ref_seq.seq_align_beg               1\n",
      "_struct_ref_seq.seq_align_end               89\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def blocks_between_hashtags(file_content):\n",
    "    \n",
    "    in_block = False\n",
    "    blocks = []\n",
    "    current_block = []\n",
    "\n",
    "    for line in file_content:\n",
    "        line = line.strip()\n",
    "\n",
    "        if line == '#':\n",
    "            if in_block:\n",
    "                if current_block:\n",
    "                    blocks.append('\\n'.join(current_block))\n",
    "                    current_block = []\n",
    "            in_block = not in_block\n",
    "        elif in_block:\n",
    "            current_block.append(line)\n",
    "\n",
    "    return blocks\n",
    "\n",
    "cif_file_path = \"/Users/goudarzimandanagmail.com/Desktop/TransformerFromScratch/files/AF-A0A1D8PD42-F1-model_v4.cif\"\n",
    "with open(cif_file_path, 'r') as file:\n",
    "    file_content = file.readlines()\n",
    "\n",
    "blocks = blocks_between_hashtags(file_content)\n",
    "\n",
    "for i, block in enumerate(blocks, start=1):\n",
    "    print(f\"Block {i}:\\n{block}\\n{'-'*50}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
